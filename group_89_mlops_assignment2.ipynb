{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M1: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install numpy pandas matplotlib seaborn scikit-learn shap lime joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 785)\n",
      "Testing data shape: (10000, 785)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247e5c842105475b8f2c73e84ef13652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [00:02<00:00, 349.89it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae37dab2dbdd43048f9b68f0ff9f3313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4852688dfbff49078f3585f8d8133302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7011dc0dc041b9a689a1d6d65df3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data: 0\n",
      "Missing values in test data: 0\n",
      "\n",
      "Pixel value statistics:\n",
      "             pixel1        pixel2        pixel3        pixel4        pixel5  \\\n",
      "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
      "mean       0.000900      0.006150      0.035333      0.101933      0.247967   \n",
      "std        0.094689      0.271011      1.222324      2.452871      4.306912   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max       16.000000     36.000000    226.000000    164.000000    227.000000   \n",
      "\n",
      "             pixel6        pixel7        pixel8        pixel9       pixel10  \\\n",
      "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
      "mean       0.411467      0.805767      2.198283      5.682000     14.488767   \n",
      "std        5.836188      8.215169     14.093378     23.819481     38.334549   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max      230.000000    224.000000    255.000000    254.000000    255.000000   \n",
      "\n",
      "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
      "count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n",
      "mean   ...     34.625400     23.300683     16.588267     17.869433   \n",
      "std    ...     57.545242     48.854427     41.979611     43.966032   \n",
      "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "75%    ...     58.000000      9.000000      0.000000      0.000000   \n",
      "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
      "\n",
      "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
      "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
      "mean      22.814817     17.911483      8.520633      2.753300      0.855517   \n",
      "std       51.830477     45.149388     29.614859     17.397652      9.356960   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
      "\n",
      "          pixel784  \n",
      "count  60000.00000  \n",
      "mean       0.07025  \n",
      "std        2.12587  \n",
      "min        0.00000  \n",
      "25%        0.00000  \n",
      "50%        0.00000  \n",
      "75%        0.00000  \n",
      "max      170.00000  \n",
      "\n",
      "[8 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load Fashion MNIST dataset from CSV files\n",
    "train_data = pd.read_csv(\"data/fashion-mnist_train.csv\")\n",
    "test_data = pd.read_csv(\"data/fashion-mnist_test.csv\")\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Testing data shape: {test_data.shape}\")\n",
    "\n",
    "# Assuming the label is the first column (typical format)\n",
    "# If it's in a different position, adjust accordingly\n",
    "y_train = train_data.iloc[:, 0]\n",
    "X_train = train_data.iloc[:, 1:] # pixel1 to pixel784\n",
    "y_test = test_data.iloc[:, 0]\n",
    "X_test = test_data.iloc[:, 1:] # pixel1 to pixel784\n",
    "\n",
    "# Define class names for better interpretation (classes 0-9)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Create a sample dataframe for profiling (using a subset for efficiency)\n",
    "sample_size = 5000\n",
    "df_sample = X_train.iloc[:sample_size].copy()\n",
    "df_sample['class'] = [class_names[y] for y in y_train[:sample_size]]\n",
    "\n",
    "# Generate the pandas profiling report\n",
    "profile = ProfileReport(df_sample, title=\"Fashion MNIST EDA\", \n",
    "                       minimal=True, \n",
    "                       explorative=True)\n",
    "\n",
    "# Save the report\n",
    "profile.to_file(\"output/M1_fashion_mnist_eda_report.html\")\n",
    "\n",
    "# Display class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "train_class_counts = y_train.value_counts().sort_index()\n",
    "sns.barplot(x=[class_names[i] for i in train_class_counts.index], \n",
    "            y=train_class_counts.values)\n",
    "plt.title('Class Distribution in Training Set')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/M1_class_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Display a few sample images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    img = X_train.iloc[i].values.reshape(28, 28)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(class_names[y_train.iloc[i]])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/M1_sample_images.png')\n",
    "plt.show()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in training data:\", X_train.isnull().sum().sum())\n",
    "print(\"Missing values in test data:\", X_test.isnull().sum().sum())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nPixel value statistics:\")\n",
    "pixel_stats = X_train.describe()\n",
    "print(pixel_stats)\n",
    "\n",
    "# Plot pixel intensity distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(X_train.values.flatten(), bins=50)\n",
    "plt.title('Pixel Intensity Distribution')\n",
    "plt.xlabel('Pixel Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('output/M1_pixel_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2: Feature Engineering & Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (60000, 784)\n",
      "Processed data shape: (60000, 104)\n",
      "Enhanced model accuracy: 0.8659\n",
      "Enhanced feature engineering and explainability analysis completed. Check saved visualizations.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv(\"data/fashion-mnist_train.csv\")\n",
    "test_data = pd.read_csv(\"data/fashion-mnist_test.csv\")\n",
    "\n",
    "# Split into features and target\n",
    "y_train = train_data.iloc[:, 0]\n",
    "X_train = train_data.iloc[:, 1:]\n",
    "y_test = test_data.iloc[:, 0]\n",
    "X_test = test_data.iloc[:, 1:]\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Enhanced Feature Engineering Pipeline\n",
    "def enhanced_feature_engineering_pipeline(X_train, X_test):\n",
    "    # Step 1: Normalize the data\n",
    "    X_train_norm = X_train / 255.0\n",
    "    X_test_norm = X_test / 255.0\n",
    "    \n",
    "    # Step 2: Apply PCA with more components for better feature representation\n",
    "    pca = PCA(n_components=100, random_state=42)\n",
    "    X_train_pca = pca.fit_transform(X_train_norm)\n",
    "    X_test_pca = pca.transform(X_test_norm)\n",
    "    \n",
    "    # Step 3: Add statistical features\n",
    "    X_train_stats = pd.DataFrame({\n",
    "        'mean': X_train_norm.mean(axis=1),\n",
    "        'std': X_train_norm.std(axis=1),\n",
    "        'max': X_train_norm.max(axis=1),\n",
    "        'min': X_train_norm.min(axis=1)\n",
    "    })\n",
    "    \n",
    "    X_test_stats = pd.DataFrame({\n",
    "        'mean': X_test_norm.mean(axis=1),\n",
    "        'std': X_test_norm.std(axis=1),\n",
    "        'max': X_test_norm.max(axis=1),\n",
    "        'min': X_test_norm.min(axis=1)\n",
    "    })\n",
    "    \n",
    "    # Step 4: Combine PCA and statistical features\n",
    "    X_train_combined = np.hstack([X_train_pca, X_train_stats])\n",
    "    X_test_combined = np.hstack([X_test_pca, X_test_stats])\n",
    "    \n",
    "    # Step 5: Scale the combined features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "    X_test_scaled = scaler.transform(X_test_combined)\n",
    "    \n",
    "    # Create feature names\n",
    "    feature_names = [f'pca_{i+1}' for i in range(100)] + ['mean', 'std', 'max', 'min']\n",
    "    X_train_final = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "    X_test_final = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "    \n",
    "    return X_train_final, X_test_final, pca, scaler\n",
    "\n",
    "# Apply enhanced feature engineering\n",
    "X_train_processed, X_test_processed, pca, scaler = enhanced_feature_engineering_pipeline(X_train, X_test)\n",
    "\n",
    "print(\"Original data shape:\", X_train.shape)\n",
    "print(\"Processed data shape:\", X_train_processed.shape)\n",
    "\n",
    "# Train a more sophisticated model\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)\n",
    "model.fit(X_train_processed, y_train)\n",
    "accuracy = model.score(X_test_processed, y_test)\n",
    "print(f\"Enhanced model accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Enhanced Feature Importance Analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train_processed.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(20))\n",
    "plt.title('Top 20 Important Features (Enhanced Model)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/M2_enhanced_feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "# SHAP Analysis with Enhanced Features\n",
    "X_explain = X_test_processed.iloc[:100]\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_explain)\n",
    "\n",
    "# Global SHAP Summary Plot\n",
    "plt.figure(figsize=(15, 10))\n",
    "shap.summary_plot(shap_values, X_explain, plot_type=\"bar\", class_names=class_names, show=False)\n",
    "plt.title('Global Feature Importance (SHAP Values)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/M2_enhanced_shap_summary.png')\n",
    "plt.close()\n",
    "\n",
    "# LIME Analysis\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train_processed.values,\n",
    "    feature_names=X_train_processed.columns,\n",
    "    class_names=class_names,\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Generate LIME explanations for a few examples\n",
    "for i in range(3):\n",
    "    exp = explainer.explain_instance(X_test_processed.iloc[i].values, model.predict_proba)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    exp.as_pyplot_figure()\n",
    "    plt.title(f'LIME Explanation for {class_names[y_test.iloc[i]]}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'output/M2_lime_explanation_{i}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Feature Correlation Analysis\n",
    "plt.figure(figsize=(15, 12))\n",
    "correlation_matrix = X_train_processed.corr()\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/M2_feature_correlation.png')\n",
    "plt.close()\n",
    "\n",
    "# Visualize PCA Components with Statistical Features\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(pca.components_[i].reshape(28, 28), cmap='viridis')\n",
    "    plt.title(f'PCA Component {i+1}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/M2_enhanced_pca_components.png')\n",
    "plt.close()\n",
    "\n",
    "# Save enhanced model artifacts\n",
    "import joblib\n",
    "joblib.dump(pca, 'models/enhanced_pca.joblib')\n",
    "joblib.dump(scaler, 'models/enhanced_scaler.joblib')\n",
    "joblib.dump(model, 'models/enhanced_rf_model.joblib')\n",
    "\n",
    "print(\"Enhanced feature engineering and explainability analysis completed. Check saved visualizations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M3: Model Selection & Hyperparameter Optimization - 10M   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 20:46:09,793 - model_optimization - INFO - Starting model selection and hyperparameter optimization at 2025-03-21 20:46:09.793618\n",
      "2025-03-21 20:46:09,794 - model_optimization - INFO - Trying to load preprocessed data and model artifacts...\n",
      "2025-03-21 20:46:09,795 - model_optimization - INFO - Preprocessed data not found, loading raw data and applying processing...\n",
      "2025-03-21 20:46:11,325 - model_optimization - INFO - Applying feature engineering pipeline...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (60000, 784)\n",
      "Processed data shape: (60000, 104)\n",
      "Enhanced model accuracy: 0.8659\n",
      "Enhanced feature engineering and explainability analysis completed. Check saved visualizations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 20:49:03,874 - model_optimization - INFO - Successfully processed and saved data\n",
      "2025-03-21 20:49:03,875 - model_optimization - INFO - Loaded processed training data with shape: (60000, 104)\n",
      "2025-03-21 20:49:03,875 - model_optimization - INFO - Loaded processed test data with shape: (10000, 104)\n",
      "2025-03-21 20:49:03,875 - model_optimization - INFO - Starting AutoML Model Selection Phase\n",
      "2025-03-21 20:49:03,876 - model_optimization - INFO - Training Random Forest with default parameters...\n",
      "2025-03-21 20:49:58,606 - model_optimization - INFO - Random Forest - Accuracy: 0.8655, Training Time: 54.73 seconds\n",
      "2025-03-21 20:49:58,607 - model_optimization - INFO - Training Gradient Boosting with default parameters...\n",
      "2025-03-21 21:19:47,389 - model_optimization - INFO - Gradient Boosting - Accuracy: 0.8487, Training Time: 1788.78 seconds\n",
      "2025-03-21 21:19:47,391 - model_optimization - INFO - Training XGBoost with default parameters...\n",
      "2025-03-21 21:19:55,405 - model_optimization - INFO - XGBoost - Accuracy: 0.8883, Training Time: 8.01 seconds\n",
      "2025-03-21 21:19:55,405 - model_optimization - INFO - Training LightGBM with default parameters...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26013\n",
      "[LightGBM] [Info] Number of data points in the train set: 60000, number of used features: 103\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n",
      "[LightGBM] [Info] Start training from score -2.302585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 21:20:05,279 - model_optimization - INFO - LightGBM - Accuracy: 0.8794, Training Time: 9.87 seconds\n",
      "2025-03-21 21:20:05,281 - model_optimization - INFO - Training SVM with default parameters...\n",
      "2025-03-21 21:24:45,014 - model_optimization - INFO - SVM - Accuracy: 0.9065, Training Time: 279.73 seconds\n",
      "2025-03-21 21:24:45,016 - model_optimization - INFO - Training MLP with default parameters...\n",
      "2025-03-21 21:27:03,613 - model_optimization - INFO - MLP - Accuracy: 0.8695, Training Time: 138.60 seconds\n",
      "2025-03-21 21:27:03,615 - model_optimization - INFO - Training KNN with default parameters...\n",
      "2025-03-21 21:27:04,534 - model_optimization - INFO - KNN - Accuracy: 0.8580, Training Time: 0.92 seconds\n",
      "2025-03-21 21:27:04,766 - model_optimization - INFO - Best model from AutoML phase: SVM with accuracy 0.9065\n",
      "2025-03-21 21:27:04,768 - model_optimization - INFO - Starting Hyperparameter Optimization for SVM with Optuna\n",
      "[I 2025-03-21 21:27:04,770] A new study created in memory with name: SVM_optimization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55a1082e9f0425c91b7970778a32aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 21:38:27,561] Trial 0 finished with value: 0.8192 and parameters: {'C': 0.11212367423116541, 'kernel': 'poly', 'gamma': 'auto'}. Best is trial 0 with value: 0.8192.\n",
      "[I 2025-03-21 21:56:42,584] Trial 1 finished with value: 0.8644 and parameters: {'C': 4.578870527429085, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 1 with value: 0.8644.\n",
      "[I 2025-03-21 22:05:40,123] Trial 2 finished with value: 0.863 and parameters: {'C': 0.23854952778164898, 'kernel': 'poly', 'gamma': 'auto'}. Best is trial 1 with value: 0.8644.\n",
      "[I 2025-03-21 22:10:12,422] Trial 3 finished with value: 0.8901 and parameters: {'C': 37.235771798506086, 'kernel': 'poly', 'gamma': 'scale'}. Best is trial 3 with value: 0.8901.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 22:28:53,063 - model_optimization - INFO - Trial 4: Current best: 0.890100, Recent best: 0.890100, Improvement: 0.000000\n",
      "2025-03-21 22:28:53,064 - model_optimization - INFO - Stopping optimization early: Improvement of 0.000000 is below threshold of 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 22:28:53,061] Trial 4 finished with value: 0.8644 and parameters: {'C': 4.920052966725056, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 3 with value: 0.8901.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 22:39:11,921 - model_optimization - INFO - Trial 5: Current best: 0.890100, Recent best: 0.890100, Improvement: 0.000000\n",
      "2025-03-21 22:39:11,921 - model_optimization - INFO - Stopping optimization early: Improvement of 0.000000 is below threshold of 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 22:39:11,920] Trial 5 finished with value: 0.7226 and parameters: {'C': 73.26326053111661, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 3 with value: 0.8901.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 22:43:27,633 - model_optimization - INFO - Trial 6: Current best: 0.903100, Recent best: 0.890100, Improvement: 0.013000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 22:43:27,631] Trial 6 finished with value: 0.9031 and parameters: {'C': 67.9774523809232, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 6 with value: 0.9031.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 22:47:23,218 - model_optimization - INFO - Trial 7: Current best: 0.903100, Recent best: 0.903100, Improvement: 0.000000\n",
      "2025-03-21 22:47:23,219 - model_optimization - INFO - Stopping optimization early: Improvement of 0.000000 is below threshold of 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 22:47:23,214] Trial 7 finished with value: 0.8128 and parameters: {'C': 0.16853787776975257, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 6 with value: 0.9031.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 22:49:13,349 - model_optimization - INFO - Trial 8: Current best: 0.903100, Recent best: 0.903100, Improvement: 0.000000\n",
      "2025-03-21 22:49:13,351 - model_optimization - INFO - Stopping optimization early: Improvement of 0.000000 is below threshold of 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 22:49:13,349] Trial 8 finished with value: 0.7187 and parameters: {'C': 66.507083185722, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 6 with value: 0.9031.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 22:51:12,626 - model_optimization - INFO - Trial 9: Current best: 0.903100, Recent best: 0.903100, Improvement: 0.000000\n",
      "2025-03-21 22:51:12,627 - model_optimization - INFO - Stopping optimization early: Improvement of 0.000000 is below threshold of 0.001\n",
      "2025-03-21 22:51:12,630 - model_optimization - INFO - Best hyperparameters for SVM: {'C': 67.9774523809232, 'kernel': 'rbf', 'gamma': 'scale'}\n",
      "2025-03-21 22:51:12,631 - model_optimization - INFO - Best accuracy score: 0.9031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-03-21 22:51:12,625] Trial 9 finished with value: 0.7324 and parameters: {'C': 3.691156918315294, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 6 with value: 0.9031.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 22:51:12,970 - model_optimization - INFO - Training final model with optimized hyperparameters...\n",
      "2025-03-21 23:10:44,058 - model_optimization - INFO - Final model accuracy: 0.9031\n",
      "2025-03-21 23:10:44,074 - model_optimization - INFO - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.82      0.86      0.84      1000\n",
      "     Trouser       0.99      0.98      0.98      1000\n",
      "    Pullover       0.83      0.83      0.83      1000\n",
      "       Dress       0.91      0.92      0.91      1000\n",
      "        Coat       0.85      0.84      0.85      1000\n",
      "      Sandal       0.98      0.97      0.98      1000\n",
      "       Shirt       0.75      0.71      0.73      1000\n",
      "     Sneaker       0.95      0.96      0.96      1000\n",
      "         Bag       0.99      0.98      0.98      1000\n",
      "  Ankle boot       0.97      0.97      0.97      1000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "2025-03-21 23:10:44,414 - model_optimization - INFO - Model improvement after optimization: -0.38%\n",
      "2025-03-21 23:10:44,420 - model_optimization - INFO - Model selection and hyperparameter optimization completed. Total time: 103.68 minutes\n",
      "2025-03-21 23:10:44,420 - model_optimization - INFO - All results and models saved to the 'output' and 'models' directories\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs('processed_data', exist_ok=True)\n",
    "os.makedirs('current_data', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('logs/M3_model_optimization.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger('model_optimization')\n",
    "\n",
    "# Start time for overall process\n",
    "start_time = time.time()\n",
    "logger.info(f\"Starting model selection and hyperparameter optimization at {datetime.now()}\")\n",
    "\n",
    "# Load the preprocessed data (assuming the feature engineering pipeline from M2 was applied)\n",
    "def load_preprocessed_data():\n",
    "    try:\n",
    "        # Try to load the already processed data\n",
    "        logger.info(\"Trying to load preprocessed data and model artifacts...\")\n",
    "        X_train_processed = pd.read_csv('processed_data/X_train_processed.csv')\n",
    "        X_test_processed = pd.read_csv('processed_data/X_test_processed.csv')\n",
    "        y_train = pd.read_csv('processed_data/y_train.csv', header=None).iloc[:, 0]\n",
    "        y_test = pd.read_csv('processed_data/y_test.csv', header=None).iloc[:, 0]\n",
    "        \n",
    "        pca = joblib.load('models/enhanced_pca.joblib')\n",
    "        scaler = joblib.load('models/enhanced_scaler.joblib')\n",
    "        \n",
    "        logger.info(\"Successfully loaded preprocessed data and model artifacts\")\n",
    "    except (FileNotFoundError, IOError):\n",
    "        logger.info(\"Preprocessed data not found, loading raw data and applying processing...\")\n",
    "        \n",
    "        # Load raw data\n",
    "        train_data = pd.read_csv(\"data/fashion-mnist_train.csv\")\n",
    "        test_data = pd.read_csv(\"data/fashion-mnist_test.csv\")\n",
    "        \n",
    "        # Split into features and target\n",
    "        y_train = train_data.iloc[:, 0]\n",
    "        X_train = train_data.iloc[:, 1:]\n",
    "        y_test = test_data.iloc[:, 0]\n",
    "        X_test = test_data.iloc[:, 1:]\n",
    "        \n",
    "        # Load the feature engineering pipeline \n",
    "        logger.info(\"Applying feature engineering pipeline...\")\n",
    "        from enhanced_feature_engineering import enhanced_feature_engineering_pipeline\n",
    "        \n",
    "        X_train_processed, X_test_processed, pca, scaler = enhanced_feature_engineering_pipeline(X_train, X_test)\n",
    "        \n",
    "        # Save the processed data for future use\n",
    "        X_train_processed.to_csv('processed/X_train_processed.csv', index=False)\n",
    "        X_test_processed.to_csv('processed/X_test_processed.csv', index=False)\n",
    "        y_train.to_csv('data/y_train.csv', index=False, header=False)\n",
    "        y_test.to_csv('data/y_test.csv', index=False, header=False)\n",
    "        \n",
    "        logger.info(\"Successfully processed and saved data\")\n",
    "    \n",
    "    return X_train_processed, X_test_processed, y_train, y_test, pca, scaler\n",
    "\n",
    "# Load data\n",
    "X_train_processed, X_test_processed, y_train, y_test, pca, scaler = load_preprocessed_data()\n",
    "\n",
    "logger.info(f\"Loaded processed training data with shape: {X_train_processed.shape}\")\n",
    "logger.info(f\"Loaded processed test data with shape: {X_test_processed.shape}\")\n",
    "\n",
    "# Define class names for better visualization\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "#-------------------------------------------------\n",
    "# Part 1: AutoML Model Selection\n",
    "#-------------------------------------------------\n",
    "\n",
    "logger.info(\"Starting AutoML Model Selection Phase\")\n",
    "\n",
    "# Define a list of candidate models with default hyperparameters\n",
    "candidate_models = [\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {'n_estimators': 100, 'max_depth': 10}\n",
    "    },\n",
    "    {\n",
    "        'name': 'Gradient Boosting',\n",
    "        'model': GradientBoostingClassifier(random_state=42),\n",
    "        'params': {'n_estimators': 100, 'learning_rate': 0.1}\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGBoost',\n",
    "        'model': XGBClassifier(random_state=42),\n",
    "        'params': {'n_estimators': 100, 'learning_rate': 0.1}\n",
    "    },\n",
    "    {\n",
    "        'name': 'LightGBM',\n",
    "        'model': LGBMClassifier(random_state=42),\n",
    "        'params': {'n_estimators': 100, 'learning_rate': 0.1}\n",
    "    },\n",
    "    {\n",
    "        'name': 'SVM',\n",
    "        'model': SVC(probability=True, random_state=42),\n",
    "        'params': {'C': 1.0, 'kernel': 'rbf'}\n",
    "    },\n",
    "    {\n",
    "        'name': 'MLP',\n",
    "        'model': MLPClassifier(random_state=42),\n",
    "        'params': {'hidden_layer_sizes': (100,), 'max_iter': 300}\n",
    "    },\n",
    "    {\n",
    "        'name': 'KNN',\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {'n_neighbors': 5}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Evaluate each model and collect results\n",
    "automl_results = []\n",
    "\n",
    "for model_info in candidate_models:\n",
    "    model_name = model_info['name']\n",
    "    model = model_info['model']\n",
    "    \n",
    "    logger.info(f\"Training {model_name} with default parameters...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Save results\n",
    "    result = {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'train_time': train_time\n",
    "    }\n",
    "    automl_results.append(result)\n",
    "    \n",
    "    logger.info(f\"{model_name} - Accuracy: {accuracy:.4f}, Training Time: {train_time:.2f} seconds\")\n",
    "\n",
    "# Convert results to DataFrame for easier visualization\n",
    "automl_df = pd.DataFrame(automl_results)\n",
    "automl_df = automl_df.sort_values('accuracy', ascending=False)\n",
    "\n",
    "# Save results\n",
    "automl_df.to_csv('output/M3_automl_results.csv', index=False)\n",
    "\n",
    "# Visualize AutoML results\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_plot = sns.barplot(x='model_name', y='accuracy', data=automl_df)\n",
    "plt.title('Model Comparison - Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/M3_automl_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Visualize training time\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_plot = sns.barplot(x='model_name', y='train_time', data=automl_df)\n",
    "plt.title('Model Comparison - Training Time (seconds)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/M3_automl_training_time.png')\n",
    "plt.close()\n",
    "\n",
    "# Select the best model from AutoML\n",
    "best_model_name = automl_df.iloc[0]['model_name']\n",
    "best_model_accuracy = automl_df.iloc[0]['accuracy']\n",
    "\n",
    "logger.info(f\"Best model from AutoML phase: {best_model_name} with accuracy {best_model_accuracy:.4f}\")\n",
    "\n",
    "# Find the corresponding model object from our candidate_models list\n",
    "best_model = next(model_info['model'] for model_info in candidate_models if model_info['name'] == best_model_name)\n",
    "\n",
    "#-------------------------------------------------\n",
    "# Part 2: Hyperparameter Optimization with Optuna\n",
    "#-------------------------------------------------\n",
    "\n",
    "logger.info(f\"Starting Hyperparameter Optimization for {best_model_name} with Optuna\")\n",
    "\n",
    "# Define hyperparameter search spaces based on the best model\n",
    "def get_param_search_space(model_name):\n",
    "    if model_name == 'Random Forest':\n",
    "        def objective(trial):\n",
    "            n_estimators = trial.suggest_int('n_estimators', 50, 1000, step=50)\n",
    "            max_depth = trial.suggest_int('max_depth', 5, 30, step=5)\n",
    "            min_samples_split = trial.suggest_int('min_samples_split', 2, 20, step=2)\n",
    "            min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "            max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "            \n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                min_samples_split=min_samples_split,\n",
    "                min_samples_leaf=min_samples_leaf,\n",
    "                max_features=max_features,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train_processed, y_train)\n",
    "            y_pred = model.predict(X_test_processed)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            return accuracy\n",
    "    \n",
    "    elif model_name == 'Gradient Boosting':\n",
    "        def objective(trial):\n",
    "            n_estimators = trial.suggest_int('n_estimators', 50, 500, step=50)\n",
    "            learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "            max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "            min_samples_split = trial.suggest_int('min_samples_split', 2, 20, step=2)\n",
    "            subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "            \n",
    "            model = GradientBoostingClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate,\n",
    "                max_depth=max_depth,\n",
    "                min_samples_split=min_samples_split,\n",
    "                subsample=subsample,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train_processed, y_train)\n",
    "            y_pred = model.predict(X_test_processed)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            return accuracy\n",
    "    \n",
    "    elif model_name == 'XGBoost':\n",
    "        def objective(trial):\n",
    "            n_estimators = trial.suggest_int('n_estimators', 50, 500, step=50)\n",
    "            learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "            max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "            subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "            colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "            \n",
    "            model = XGBClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate,\n",
    "                max_depth=max_depth,\n",
    "                subsample=subsample,\n",
    "                colsample_bytree=colsample_bytree,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train_processed, y_train)\n",
    "            y_pred = model.predict(X_test_processed)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            return accuracy\n",
    "    \n",
    "    elif model_name == 'LightGBM':\n",
    "        def objective(trial):\n",
    "            n_estimators = trial.suggest_int('n_estimators', 50, 500, step=50)\n",
    "            learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "            max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "            num_leaves = trial.suggest_int('num_leaves', 20, 100, step=10)\n",
    "            subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "            colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "            \n",
    "            model = LGBMClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                learning_rate=learning_rate,\n",
    "                max_depth=max_depth,\n",
    "                num_leaves=num_leaves,\n",
    "                subsample=subsample,\n",
    "                colsample_bytree=colsample_bytree,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train_processed, y_train)\n",
    "            y_pred = model.predict(X_test_processed)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            return accuracy\n",
    "    \n",
    "    elif model_name == 'SVM':\n",
    "        def objective(trial):\n",
    "            C = trial.suggest_float('C', 0.1, 100.0, log=True)\n",
    "            kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "            gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "            \n",
    "            model = SVC(\n",
    "                C=C,\n",
    "                kernel=kernel,\n",
    "                gamma=gamma,\n",
    "                probability=True,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train_processed, y_train)\n",
    "            y_pred = model.predict(X_test_processed)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            return accuracy\n",
    "    \n",
    "    elif model_name == 'MLP':\n",
    "        def objective(trial):\n",
    "            hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [\n",
    "                (50,), (100,), (50, 50), (100, 50), (100, 100)\n",
    "            ])\n",
    "            activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "            alpha = trial.suggest_float('alpha', 1e-5, 1e-2, log=True)\n",
    "            learning_rate_init = trial.suggest_float('learning_rate_init', 1e-4, 1e-1, log=True)\n",
    "            max_iter = trial.suggest_int('max_iter', 100, 500, step=100)\n",
    "            \n",
    "            model = MLPClassifier(\n",
    "                hidden_layer_sizes=hidden_layer_sizes,\n",
    "                activation=activation,\n",
    "                alpha=alpha,\n",
    "                learning_rate_init=learning_rate_init,\n",
    "                max_iter=max_iter,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train_processed, y_train)\n",
    "            y_pred = model.predict(X_test_processed)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            return accuracy\n",
    "\n",
    "    elif model_name == 'KNN':\n",
    "        def objective(trial):\n",
    "            n_neighbors = trial.suggest_int('n_neighbors', 1, 20)\n",
    "            weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "            algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "            p = trial.suggest_int('p', 1, 2)  # p=1 for manhattan_distance, p=2 for euclidean_distance\n",
    "            \n",
    "            model = KNeighborsClassifier(\n",
    "                n_neighbors=n_neighbors,\n",
    "                weights=weights,\n",
    "                algorithm=algorithm,\n",
    "                p=p\n",
    "            )\n",
    "            \n",
    "            model.fit(X_train_processed, y_train)\n",
    "            y_pred = model.predict(X_test_processed)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            return accuracy\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not supported for hyperparameter tuning\")\n",
    "    \n",
    "    return objective\n",
    "\n",
    "# Get the objective function for the best model\n",
    "objective = get_param_search_space(best_model_name)\n",
    "\n",
    "# Create a new Optuna study\n",
    "study = optuna.create_study(direction='maximize', study_name=f'{best_model_name}_optimization')\n",
    "\n",
    "# Define early stopping callback\n",
    "def early_stopping_callback(study, trial):\n",
    "    \"\"\"Stop optimization if no improvement in the last several trials.\"\"\"\n",
    "    \n",
    "    # Parameters for early stopping\n",
    "    n_warmup = 3  # Minimum number of trials before checking for early stopping\n",
    "    n_patience = 3  # Number of trials to wait for improvement\n",
    "    min_improvement = 0.001  # Minimum improvement in accuracy considered meaningful\n",
    "    \n",
    "    # Skip early stopping if we haven't done enough trials\n",
    "    if trial.number <= n_warmup:\n",
    "        return False\n",
    "        \n",
    "    # Get completed trials with values\n",
    "    completed_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE and t.value is not None]\n",
    "    if len(completed_trials) <= n_warmup:\n",
    "        return False\n",
    "    \n",
    "    # Current best value\n",
    "    best_value = study.best_value\n",
    "    \n",
    "    # Check if there's been a meaningful improvement in the last n_patience trials\n",
    "    recent_best = max([t.value for t in completed_trials[-n_patience-1:-1] if t.value is not None], default=0)\n",
    "    \n",
    "    # Calculate improvement\n",
    "    improvement = best_value - recent_best\n",
    "    \n",
    "    # Log the improvement\n",
    "    logger.info(f\"Trial {trial.number}: Current best: {best_value:.6f}, Recent best: {recent_best:.6f}, Improvement: {improvement:.6f}\")\n",
    "    \n",
    "    # If improvement is very small or negative, stop\n",
    "    if improvement < min_improvement:\n",
    "        logger.info(f\"Stopping optimization early: Improvement of {improvement:.6f} is below threshold of {min_improvement}\")\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Run the optimization with early stopping\n",
    "study.optimize(objective, n_trials=10, show_progress_bar=True, callbacks=[early_stopping_callback])\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params = study.best_params\n",
    "best_score = study.best_value\n",
    "\n",
    "logger.info(f\"Best hyperparameters for {best_model_name}: {best_params}\")\n",
    "logger.info(f\"Best accuracy score: {best_score:.4f}\")\n",
    "\n",
    "# Plot optimization history\n",
    "plt.figure(figsize=(10, 6))\n",
    "optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "plt.title(f'Optimization History for {best_model_name}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/M3_optuna_optimization_history.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot parameter importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "optuna.visualization.matplotlib.plot_param_importances(study)\n",
    "plt.title(f'Parameter Importances for {best_model_name}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/M3_optuna_param_importances.png')\n",
    "plt.close()\n",
    "\n",
    "# Create the final model with the best hyperparameters\n",
    "if best_model_name == 'Random Forest':\n",
    "    final_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    final_model = GradientBoostingClassifier(**best_params, random_state=42)\n",
    "elif best_model_name == 'XGBoost':\n",
    "    final_model = XGBClassifier(**best_params, random_state=42)\n",
    "elif best_model_name == 'LightGBM':\n",
    "    final_model = LGBMClassifier(**best_params, random_state=42)\n",
    "elif best_model_name == 'SVM':\n",
    "    final_model = SVC(**best_params, probability=True, random_state=42)\n",
    "elif best_model_name == 'MLP':\n",
    "    final_model = MLPClassifier(**best_params, random_state=42)\n",
    "elif best_model_name == 'KNN':\n",
    "    final_model = KNeighborsClassifier(**best_params)\n",
    "\n",
    "# Train the final model\n",
    "logger.info(\"Training final model with optimized hyperparameters...\")\n",
    "final_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Evaluate the final model\n",
    "y_pred = final_model.predict(X_test_processed)\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "logger.info(f\"Final model accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred, target_names=class_names)\n",
    "logger.info(f\"Classification Report:\\n{report}\")\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'Confusion Matrix - {best_model_name} (Optimized)')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/M3_confusion_matrix_optimized.png')\n",
    "plt.close()\n",
    "\n",
    "# Save the final model\n",
    "joblib.dump(final_model, f'models/optimized_{best_model_name.lower().replace(\" \", \"_\")}.joblib')\n",
    "\n",
    "# Calculate improvement from default to optimized\n",
    "default_accuracy = best_model_accuracy\n",
    "improvement = ((final_accuracy - default_accuracy) / default_accuracy) * 100\n",
    "\n",
    "logger.info(f\"Model improvement after optimization: {improvement:.2f}%\")\n",
    "\n",
    "# Create a dictionary to store model metadata\n",
    "model_metadata = {\n",
    "    'model_name': best_model_name,\n",
    "    'default_accuracy': default_accuracy,\n",
    "    'optimized_accuracy': final_accuracy,\n",
    "    'improvement_percentage': improvement,\n",
    "    'best_hyperparameters': best_params,\n",
    "    'feature_count': X_train_processed.shape[1],\n",
    "    'training_samples': X_train_processed.shape[0],\n",
    "    'test_samples': X_test_processed.shape[0]\n",
    "}\n",
    "\n",
    "# Save model metadata as JSON\n",
    "import json\n",
    "with open('models/optimized_model_metadata.json', 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=4)\n",
    "\n",
    "# Generate model selection and optimization summary\n",
    "with open('output/M3_model_optimization_summary.txt', 'w') as f:\n",
    "    f.write(\"# Model Selection and Hyperparameter Optimization Summary\\n\\n\")\n",
    "    f.write(f\"## AutoML Model Selection Results\\n\")\n",
    "    f.write(automl_df.to_string(index=False))\n",
    "    f.write(\"\\n\\n\")\n",
    "    f.write(f\"## Best Model Selected: {best_model_name}\\n\")\n",
    "    f.write(f\"Default accuracy: {default_accuracy:.4f}\\n\\n\")\n",
    "    f.write(\"## Hyperparameter Optimization\\n\")\n",
    "    f.write(f\"Optimization method: Optuna\\n\")\n",
    "    f.write(f\"Number of trials: {len(study.trials)}\\n\\n\")\n",
    "    f.write(\"## Best Hyperparameters\\n\")\n",
    "    for param, value in best_params.items():\n",
    "        f.write(f\"- {param}: {value}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"## Final Performance\\n\")\n",
    "    f.write(f\"Optimized accuracy: {final_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Improvement: {improvement:.2f}%\\n\\n\")\n",
    "    f.write(\"## Classification Report\\n\")\n",
    "    f.write(report)\n",
    "\n",
    "logger.info(f\"Model selection and hyperparameter optimization completed. Total time: {(time.time() - start_time)/60:.2f} minutes\")\n",
    "logger.info(f\"All results and models saved to the 'output' and 'models' directories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M4: Model Monitoring & Performance Tracking Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from scipy.stats import ks_2samp\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('logs/model_monitoring.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger('model_monitoring')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "os.makedirs('drift_reports', exist_ok=True)\n",
    "\n",
    "# MLflow setup\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"Fashion-MNIST-Monitoring\")\n",
    "\n",
    "class ModelMonitor:\n",
    "    def __init__(self, model_path, model_name, reference_data_path, current_data_path):\n",
    "        \"\"\"Initialize the model monitor with paths to the model and data\"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.model_name = model_name\n",
    "        self.reference_data_path = reference_data_path\n",
    "        self.current_data_path = current_data_path\n",
    "        self.model = self._load_model()\n",
    "        self.reference_data = self._load_data(reference_data_path)\n",
    "        self.current_data = self._load_data(current_data_path)\n",
    "        self.performance_metrics = {}\n",
    "        self.drift_metrics = {}\n",
    "        \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the trained model from disk\"\"\"\n",
    "        try:\n",
    "            model = joblib.load(self.model_path)\n",
    "            logger.info(f\"Successfully loaded model from {self.model_path}\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "            \n",
    "    def _load_data(self, data_path):\n",
    "        \"\"\"Load dataset (features and labels)\"\"\"\n",
    "        try:\n",
    "            data = {}\n",
    "            data['X'] = pd.read_csv(f\"{data_path}/X_test_processed.csv\")\n",
    "            data['y'] = pd.read_csv(f\"{data_path}/y_test.csv\", header=None).iloc[:, 0]\n",
    "            logger.info(f\"Successfully loaded data from {data_path}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def evaluate_performance(self):\n",
    "        \"\"\"Evaluate model performance on current data\"\"\"\n",
    "        X = self.current_data['X']\n",
    "        y_true = self.current_data['y']\n",
    "        \n",
    "        # Generate predictions\n",
    "        y_pred = self.model.predict(X)\n",
    "        \n",
    "        # For multi-class classification\n",
    "        try:\n",
    "            y_prob = self.model.predict_proba(X)\n",
    "        except:\n",
    "            y_prob = None\n",
    "            \n",
    "        # Calculate metrics\n",
    "        self.performance_metrics = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision_macro': precision_score(y_true, y_pred, average='macro'),\n",
    "            'recall_macro': recall_score(y_true, y_pred, average='macro'),\n",
    "            'f1_macro': f1_score(y_true, y_pred, average='macro'),\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'data_size': len(X)\n",
    "        }\n",
    "        \n",
    "        if y_prob is not None:\n",
    "            # For multiclass, calculate weighted AUC\n",
    "            self.performance_metrics['roc_auc'] = roc_auc_score(\n",
    "                pd.get_dummies(y_true), y_prob, average='weighted', multi_class='ovr'\n",
    "            )\n",
    "        \n",
    "        # Generate confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        class_names = [f'class{i}' for i in range(10)]  # Assuming 10 classes for Fashion-MNIST\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title(f'Confusion Matrix - {self.model_name}')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save confusion matrix\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        cm_path = f\"logs/confusion_matrix_{timestamp}.png\"\n",
    "        plt.savefig(cm_path)\n",
    "        plt.close()\n",
    "        \n",
    "        self.performance_metrics['confusion_matrix_path'] = cm_path\n",
    "        \n",
    "        # Log detailed classification report\n",
    "        report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "        logger.info(f\"Classification Report:\\n{report}\")\n",
    "        \n",
    "        logger.info(f\"Performance metrics: {self.performance_metrics}\")\n",
    "        return self.performance_metrics\n",
    "    \n",
    "    def detect_drift(self, threshold=0.05):\n",
    "        \"\"\"Detect feature drift between reference and current datasets\"\"\"\n",
    "        X_ref = self.reference_data['X']\n",
    "        X_curr = self.current_data['X']\n",
    "        \n",
    "        drift_detected = False\n",
    "        drift_features = []\n",
    "        ks_statistics = {}\n",
    "        \n",
    "        # Iterate through each feature and apply Kolmogorov-Smirnov test\n",
    "        for column in X_ref.columns:\n",
    "            ks_stat, p_value = ks_2samp(X_ref[column], X_curr[column])\n",
    "            ks_statistics[column] = {'ks_statistic': ks_stat, 'p_value': p_value}\n",
    "            \n",
    "            # If p-value is below threshold, we consider the distributions different\n",
    "            if p_value < threshold:\n",
    "                drift_features.append(column)\n",
    "        \n",
    "        if len(drift_features) > 0:\n",
    "            drift_detected = True\n",
    "            logger.warning(f\"Drift detected in {len(drift_features)} features: {drift_features[:5]}...\")\n",
    "        \n",
    "        # Calculate overall drift percentage\n",
    "        drift_percentage = len(drift_features) / len(X_ref.columns) * 100\n",
    "        \n",
    "        self.drift_metrics = {\n",
    "            'drift_detected': drift_detected,\n",
    "            'drift_percentage': drift_percentage,\n",
    "            'drifted_features_count': len(drift_features),\n",
    "            'drifted_features': drift_features[:10],  # List first 10 drifted features\n",
    "            'threshold': threshold,\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        # Generate drift visualization for top drifted features\n",
    "        self._visualize_drift(drift_features[:5], ks_statistics)\n",
    "        \n",
    "        logger.info(f\"Drift metrics: {self.drift_metrics}\")\n",
    "        return self.drift_metrics\n",
    "    \n",
    "    def _visualize_drift(self, drift_features, ks_statistics):\n",
    "        \"\"\"Visualize distribution drift for top drifted features\"\"\"\n",
    "        X_ref = self.reference_data['X']\n",
    "        X_curr = self.current_data['X']\n",
    "        \n",
    "        n_features = len(drift_features)\n",
    "        if n_features == 0:\n",
    "            logger.info(\"No drift detected for visualization\")\n",
    "            return\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        drift_report_path = f\"drift_reports/drift_report_{timestamp}.png\"\n",
    "        \n",
    "        fig, axes = plt.subplots(n_features, 1, figsize=(12, 4 * n_features))\n",
    "        if n_features == 1:\n",
    "            axes = [axes]\n",
    "            \n",
    "        for i, feature in enumerate(drift_features):\n",
    "            ax = axes[i]\n",
    "            \n",
    "            # Plot histograms for reference and current data\n",
    "            sns.histplot(X_ref[feature], color=\"blue\", alpha=0.5, \n",
    "                         label=\"Reference Data\", ax=ax)\n",
    "            sns.histplot(X_curr[feature], color=\"red\", alpha=0.5, \n",
    "                         label=\"Current Data\", ax=ax)\n",
    "            \n",
    "            # Add KS statistic and p-value to plot\n",
    "            ks_stat = ks_statistics[feature]['ks_statistic']\n",
    "            p_value = ks_statistics[feature]['p_value']\n",
    "            ax.set_title(f\"Feature: {feature} - KS Stat: {ks_stat:.4f}, p-value: {p_value:.4e}\")\n",
    "            ax.legend()\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(drift_report_path)\n",
    "        plt.close()\n",
    "        \n",
    "        self.drift_metrics['visualization_path'] = drift_report_path\n",
    "        logger.info(f\"Drift visualization saved to {drift_report_path}\")\n",
    "    \n",
    "    def log_to_mlflow(self):\n",
    "        \"\"\"Log metrics, parameters, and artifacts to MLflow\"\"\"\n",
    "        with mlflow.start_run(run_name=f\"{self.model_name}_monitoring_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
    "            # Log model performance metrics\n",
    "            for metric_name, metric_value in self.performance_metrics.items():\n",
    "                if isinstance(metric_value, (int, float)):\n",
    "                    mlflow.log_metric(metric_name, metric_value)\n",
    "            \n",
    "            # Log drift metrics\n",
    "            if self.drift_metrics:\n",
    "                mlflow.log_param(\"drift_detected\", self.drift_metrics['drift_detected'])\n",
    "                mlflow.log_metric(\"drift_percentage\", self.drift_metrics['drift_percentage'])\n",
    "                mlflow.log_metric(\"drifted_features_count\", self.drift_metrics['drifted_features_count'])\n",
    "                \n",
    "                # Log drift report as text\n",
    "                with open(\"drift_report.json\", \"w\") as f:\n",
    "                    json.dump(self.drift_metrics, f, indent=4)\n",
    "                mlflow.log_artifact(\"drift_report.json\")\n",
    "                \n",
    "                # Log drift visualization if available\n",
    "                if 'visualization_path' in self.drift_metrics:\n",
    "                    mlflow.log_artifact(self.drift_metrics['visualization_path'])\n",
    "            \n",
    "            # Log confusion matrix\n",
    "            if 'confusion_matrix_path' in self.performance_metrics:\n",
    "                mlflow.log_artifact(self.performance_metrics['confusion_matrix_path'])\n",
    "            \n",
    "            # Log model info\n",
    "            mlflow.log_param(\"model_name\", self.model_name)\n",
    "            mlflow.log_param(\"data_size\", self.performance_metrics['data_size'])\n",
    "            mlflow.log_param(\"timestamp\", self.performance_metrics['timestamp'])\n",
    "            \n",
    "            logger.info(f\"Successfully logged metrics and artifacts to MLflow\")\n",
    "    \n",
    "    def should_retrain(self, accuracy_threshold=0.03, drift_threshold=20):\n",
    "        \"\"\"\n",
    "        Recommend if model should be retrained based on:\n",
    "        1. Performance degradation compared to reference\n",
    "        2. Significant data drift\n",
    "        \"\"\"\n",
    "        # Get reference performance (can be stored separately in a better system)\n",
    "        try:\n",
    "            with open('models/optimized_model_metadata.json', 'r') as f:\n",
    "                reference_metadata = json.load(f)\n",
    "                reference_accuracy = reference_metadata.get('optimized_accuracy', 0)\n",
    "        except:\n",
    "            logger.warning(\"Could not find reference performance, using 0.9 as default\")\n",
    "            reference_accuracy = 0.9\n",
    "        \n",
    "        current_accuracy = self.performance_metrics['accuracy']\n",
    "        accuracy_drop = reference_accuracy - current_accuracy\n",
    "        \n",
    "        drift_percentage = self.drift_metrics.get('drift_percentage', 0)\n",
    "        \n",
    "        retrain_reasons = []\n",
    "        \n",
    "        if accuracy_drop > accuracy_threshold:\n",
    "            retrain_reasons.append(\n",
    "                f\"Performance drop: {accuracy_drop:.4f} (threshold: {accuracy_threshold})\")\n",
    "        \n",
    "        if drift_percentage > drift_threshold:\n",
    "            retrain_reasons.append(\n",
    "                f\"Feature drift: {drift_percentage:.2f}% (threshold: {drift_threshold}%)\")\n",
    "        \n",
    "        should_retrain = len(retrain_reasons) > 0\n",
    "        \n",
    "        retrain_info = {\n",
    "            \"retrain_recommended\": should_retrain,\n",
    "            \"reasons\": retrain_reasons,\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"accuracy_drop\": accuracy_drop,\n",
    "            \"drift_percentage\": drift_percentage\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Retrain recommendation: {retrain_info}\")\n",
    "        \n",
    "        # Save recommendation to file\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        with open(f\"logs/retrain_recommendation_{timestamp}.json\", \"w\") as f:\n",
    "            json.dump(retrain_info, f, indent=4)\n",
    "        \n",
    "        return retrain_info\n",
    "\n",
    "# Sample execution (you would typically run this on a schedule)\n",
    "def run_monitoring_pipeline():\n",
    "    logger.info(\"Starting model monitoring pipeline\")\n",
    "    \n",
    "    # Define paths\n",
    "    model_path = \"models/optimized_svm.joblib\"  # Update with your actual model name\n",
    "    model_name = \"SVM\"  # Update with your model name\n",
    "    \n",
    "    # Reference data is your original training/validation data\n",
    "    reference_data_path = \"processed_data\"\n",
    "    \n",
    "    # Current data is your new production data\n",
    "    current_data_path = \"current_data\"\n",
    "    \n",
    "    # Initialize model monitor\n",
    "    try:\n",
    "        monitor = ModelMonitor(model_path, model_name, reference_data_path, current_data_path)\n",
    "        \n",
    "        # Evaluate model performance\n",
    "        performance = monitor.evaluate_performance()\n",
    "        \n",
    "        # Detect data drift\n",
    "        drift = monitor.detect_drift(threshold=0.05)\n",
    "        \n",
    "        # Log to MLflow\n",
    "        monitor.log_to_mlflow()\n",
    "        \n",
    "        # Get retraining recommendation\n",
    "        retrain_info = monitor.should_retrain(accuracy_threshold=0.03, drift_threshold=20)\n",
    "        \n",
    "        logger.info(\"Model monitoring pipeline completed successfully\")\n",
    "        return {\n",
    "            \"performance\": performance,\n",
    "            \"drift\": drift,\n",
    "            \"retrain_info\": retrain_info\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in monitoring pipeline: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # This would be scheduled to run periodically\n",
    "    run_monitoring_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the following in the terminal to access the mlops UI\n",
    "\n",
    "#### \"mlflow ui --backend-store-uri sqlite:///mlflow.db\" ####"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
